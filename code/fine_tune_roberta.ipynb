{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa Machine Generated Text Classifier\n",
    "\n",
    "Follows:\n",
    "> Adaku Uchendu, Thai Le, Kai Shu, and Dongwon Lee. 2020. [Authorship Attribution for Neural Text Generation](https://aclanthology.org/2020.emnlp-main.673/). In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8384â€“8395, Online. Association for Computational Linguistics.\n",
    "\n",
    "Download training data from [here](https://raw.githubusercontent.com/AdaUchendu/Authorship-Attribution-for-Neural-Text-Generation/master/data/balanced_p2.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import set_seed\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments,AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.read_csv('balanced_p2.csv', index_col=0).reset_index(drop=True)\n",
    "balanced_df.rename(columns={'class': 'label'}, inplace=True)\n",
    "train_df, test_df = train_test_split(balanced_df, test_size=0.2, random_state=13, stratify=balanced_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and validation data\n",
    "train_texts = train_df.text.tolist()\n",
    "train_labels = train_df.label.tolist()\n",
    "val_texts = test_df.text.tolist()\n",
    "val_labels = test_df.label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'eval_accuracy': acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True, max_length=512, pad_to_multiple_of=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./models',\n",
    "    num_train_epochs=10 ,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"eval_f1\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "val_dataset = CustomDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,    \n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.best_model_checkpoint, trainer.state.best_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(trainer.state.best_model_checkpoint)\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_text):\n",
    "    # Tokenize the input text\n",
    "    input_encodings = tokenizer(input_text, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate predictions for the input text\n",
    "    with torch.no_grad():\n",
    "        logits = model(**input_encodings).logits\n",
    "\n",
    "    # Get the predicted label\n",
    "    pred_label = logits.argmax().item()\n",
    "    pred_prob = logits.softmax(dim=1).max().item()\n",
    "    return pred_label, pred_prob\n",
    "\n",
    "\n",
    "# Define the input text to be classified\n",
    "input_text = \"Text to test\"\n",
    "predict(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_df = pd.read_csv(\"../priv_data/chatgpt-general.csv\", index_col=0)\n",
    "general_df['source'] = 'chatgpt-general'\n",
    "topic_df = pd.read_csv(\"../priv_data/chatgpt-topic.csv\", index_col=0)\n",
    "topic_df['source'] = 'chatgpt-topic'\n",
    "claimreview_df = pd.read_csv(\"../priv_data/claimreview.csv\", index_col=0)\n",
    "claimreview_df['source'] = 'claimreview'\n",
    "\n",
    "all_df = pd.concat([general_df, topic_df, claimreview_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are human=0, machine=1.\n",
    "See cell 56 in [this notebook](https://github.com/AdaUchendu/Authorship-Attribution-for-Neural-Text-Generation/blob/dd0ed003dc4db7979f34f9480636d4417d9a827a/Clean_Generated/Single/P2%20Binary%20-%20Human%20vs%20Machine.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['true_label'] = all_df['source'].apply(lambda x: 0 if x == 'claimreview' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['true_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "probs = []\n",
    "for claim in tqdm(all_df['claim'].tolist()):\n",
    "    label, prob = predict(claim)\n",
    "    predictions.append(label)\n",
    "    probs.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['pred'] = predictions\n",
    "all_df['prob'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_general_df = all_df[all_df['source'] == 'chatgpt-general']\n",
    "f1_score(r_general_df['true_label'] == 1, r_general_df['pred'] == 1, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_topic_df = all_df[all_df['source'] == 'chatgpt-topic']\n",
    "f1_score(r_topic_df['true_label'] == 1, r_topic_df['pred'] == 1, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cr_df = all_df[all_df['source'] == 'claimreview']\n",
    "f1_score(r_cr_df['true_label'] == 0, r_cr_df['pred'] == 0, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(all_df['true_label'], all_df['pred'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['prob'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disinfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
